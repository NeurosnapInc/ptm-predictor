{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fece81-d522-46f2-9e4c-cab9bee855ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PTM Adapter Model...\n",
      "Input shape: torch.Size([3, 402])\n",
      "Output shape: torch.Size([3, 402, 10])\n",
      "Logits range: [-45.447, 38.840]\n",
      "Probabilities sum: 1.000\n",
      "Loss: 17.5419\n",
      "Adapter gradient norm: 0.000220\n",
      "Classifier gradient norm: 333.558075\n",
      "ESM gradients (should be 0): 0\n",
      "Total parameters: 651,223,809\n",
      "Trainable parameters: 180,555\n",
      "Trainable ratio: 0.0%\n",
      "Test complete!\n"
     ]
    }
   ],
   "source": [
    "# For testing model.py\n",
    "import torch\n",
    "from models.model import ptm_model, batch_converter\n",
    "\n",
    "print(\"Testing PTM Adapter Model...\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "ptm_model.eval()\n",
    "\n",
    "# Create sample protein sequences\n",
    "sample_sequences = [\n",
    "    (\"protein1\", \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"),\n",
    "    (\"protein2\", \"ARNDCEQGHILKMFPSTWYV\" * 20),\n",
    "    (\"protein3\", \"MKLLNVINFVFLMFVSSGRGMSVRGQSQDIVCPITCGQDLKKLGLCATLVVAGMVNPNAZK\")\n",
    "]\n",
    "\n",
    "# Convert sequences to tokens\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(sample_sequences)\n",
    "\n",
    "print(f\"Input shape: {batch_tokens.shape}\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    logits = ptm_model(batch_tokens)\n",
    "    print(f\"Output shape: {logits.shape}\")\n",
    "    print(f\"Logits range: [{logits.min().item():.3f}, {logits.max().item():.3f}]\")\n",
    "    \n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    print(f\"Probabilities sum: {probs.sum(dim=-1)[0][1].item():.3f}\")\n",
    "\n",
    "# Test gradient computation\n",
    "ptm_model.train()\n",
    "batch_size, seq_len = batch_tokens.shape\n",
    "dummy_targets = torch.randint(0, 10, (batch_size, seq_len))\n",
    "\n",
    "logits = ptm_model(batch_tokens)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits.view(-1, 10), dummy_targets.view(-1))\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "adapter_grad_norm = torch.norm(torch.cat([p.grad.flatten() for p in ptm_model.adapter.parameters() if p.grad is not None]))\n",
    "classifier_grad_norm = torch.norm(torch.cat([p.grad.flatten() for p in ptm_model.ptm_classifier.parameters() if p.grad is not None]))\n",
    "\n",
    "print(f\"Adapter gradient norm: {adapter_grad_norm.item():.6f}\")\n",
    "print(f\"Classifier gradient norm: {classifier_grad_norm.item():.6f}\")\n",
    "\n",
    "# Check ESM parameters are frozen\n",
    "esm_grads = [p.grad for p in ptm_model.esm_model.parameters() if p.grad is not None]\n",
    "print(f\"ESM gradients (should be 0): {len(esm_grads)}\")\n",
    "\n",
    "# Parameter summary\n",
    "total_params = sum(p.numel() for p in ptm_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in ptm_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Trainable ratio: {trainable_params/total_params:.1%}\")\n",
    "\n",
    "print(\"Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9824a2f-6c26-43d0-9c4a-b92b4dda4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing data_loader.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from esm import pretrained\n",
    "import sys\n",
    "sys.path.append('utils')\n",
    "from data_loader import PTMDataset, collate_fn, get_data_loaders\n",
    "\n",
    "def test_dataset_creation(csv_path):\n",
    "    print(f\"Testing PTMDataset with {csv_path}\")\n",
    "    \n",
    "    # Load ESM model components\n",
    "    esm_model, alphabet = pretrained.esm2_t33_650M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    print(\"✓ ESM2 model loaded successfully\")\n",
    "    \n",
    "    # Load and inspect CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"✓ CSV loaded successfully\")\n",
    "    print(len(df))\n",
    "    print(f\"Sample positions: {df['positions'].iloc[0]}\")\n",
    "    \n",
    "    # Test dataset creation\n",
    "    print(\"Creating PTMDataset...\")\n",
    "    dataset = PTMDataset(csv_path, alphabet, batch_converter)\n",
    "    print(f\"✓ Dataset created successfully\")\n",
    "    print(f\"Dataset length: {len(dataset)}\")\n",
    "    print(f\"Number of PTM types: {dataset.num_ptm_types}\")\n",
    "    print()\n",
    "    \n",
    "    return dataset, alphabet, batch_converter\n",
    "\n",
    "def test_dataset_items(dataset):\n",
    "    print(\"Testing Dataset Items\")\n",
    "    \n",
    "    # Test getting items\n",
    "    print(\"Testing first 5 dataset items...\")\n",
    "    for i in range(min(5, len(dataset))):\n",
    "        item = dataset[i]\n",
    "        print(f\"Item {i}:\")\n",
    "        print(f\"  Sequence length: {item['seq_length']}\")\n",
    "        print(f\"  Labels shape: {item['labels'].shape}\")\n",
    "                \n",
    "        # Show PTM positions for each type\n",
    "        ptm_info = []\n",
    "        total_ptms = 0\n",
    "        for ptm_type in range(item['labels'].shape[1]):\n",
    "            positions = torch.where(item['labels'][:, ptm_type] == 1)[0].tolist()\n",
    "            ptm_info.append(f\"PTM{ptm_type}: {[p+1 for p in positions]}\")  # Convert back to 1-indexed\n",
    "            total_ptms += len(positions)\n",
    "        \n",
    "        print(f\"  Total PTMs: {total_ptms}\")\n",
    "        print(f\"  PTM positions: {ptm_info}\")\n",
    "        print()\n",
    "\n",
    "def test_collate_function(dataset, batch_converter, batch_size=5):\n",
    "    print(\"Testing Collate Function\")\n",
    "    \n",
    "    # Create a batch\n",
    "    actual_batch_size = min(batch_size, len(dataset))\n",
    "    batch = [dataset[i] for i in range(actual_batch_size)]\n",
    "    \n",
    "    print(f\"Testing collate function with batch size {len(batch)}...\")\n",
    "    print(f\"Input sequence lengths: {[item['seq_length'] for item in batch]}\")\n",
    "    \n",
    "    collated = collate_fn(batch, batch_converter)\n",
    "    \n",
    "    print(\"Collated batch contents:\")\n",
    "    print(f\"  Tokens shape: {collated['tokens'].shape}\")\n",
    "    print(f\"  Labels shape: {collated['labels'].shape}\")\n",
    "    print(f\"  Attention mask shape: {collated['attention_mask'].shape}\")\n",
    "    print(f\"  Sequence lengths: {collated['seq_lengths'].tolist()}\")\n",
    "    \n",
    "    # Verify shapes match\n",
    "    batch_size_actual, max_seq_len = collated['tokens'].shape\n",
    "    expected_labels_shape = (batch_size_actual, max_seq_len, dataset.num_ptm_types)\n",
    "    actual_labels_shape = collated['labels'].shape\n",
    "    if actual_labels_shape == expected_labels_shape:\n",
    "        print(\"✓ Shapes are consistent\")\n",
    "    else:\n",
    "        print(f\"✗ Shape mismatch: expected {expected_labels_shape}, got {actual_labels_shape}\")\n",
    "    \n",
    "    # Check token types\n",
    "    print(f\"Token analysis:\")\n",
    "    unique_tokens = torch.unique(collated['tokens']).tolist()\n",
    "    print(f\"  Padding token (1) count: {(collated['tokens'] == 1).sum().item()}\")\n",
    "    print(f\"  CLS token (0) count: {(collated['tokens'] == 0).sum().item()}\")\n",
    "    print(f\"  EOS token (2) count: {(collated['tokens'] == 2).sum().item()}\")\n",
    "    \n",
    "    # Check attention mask\n",
    "    attention_sum = collated['attention_mask'].sum(dim=1)\n",
    "    print(f\"  Attention mask sums (non-padding positions): {attention_sum.tolist()}\")\n",
    "    \n",
    "    # Verify attention mask matches sequence lengths (+2 for CLS and EOS tokens)\n",
    "    expected_attention = [seq_len + 2 for seq_len in collated['seq_lengths'].tolist()]\n",
    "    actual_attention = attention_sum.tolist()\n",
    "    \n",
    "    if expected_attention == actual_attention:\n",
    "        print(\"✓ Attention mask correctly matches sequence lengths\")\n",
    "    else:\n",
    "        print(f\"⚠️  Attention mask mismatch:\")\n",
    "        print(f\"    Expected: {expected_attention}\")\n",
    "        print(f\"    Actual: {actual_attention}\")\n",
    "    print()\n",
    "\n",
    "def test_data_loaders(train_csv, val_csv, test_csv):\n",
    "    print(\"Testing Data Loaders\")\n",
    "    \n",
    "    # Load ESM components\n",
    "    print(\"Loading ESM2 model...\")\n",
    "    esm_model, alphabet = pretrained.esm2_t33_650M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    print(\"Loaded ESM2 model\")\n",
    "    \n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        train_csv, val_csv, test_csv, \n",
    "        alphabet, batch_converter,\n",
    "        batch_size=5, num_workers=0  # Use 0 workers for testing to avoid multiprocessing issues\n",
    "    )\n",
    "    print(\"✓ Data loaders created successfully\")\n",
    "    \n",
    "    # Test iterating through loaders\n",
    "    loaders = [(\"Train\", train_loader), (\"Validation\", val_loader), (\"Test\", test_loader)]\n",
    "    \n",
    "    for loader_name, loader in loaders:\n",
    "        print(f\"Testing {loader_name.lower()} loader...\")\n",
    "        batch_count = 0\n",
    "        for i, batch in enumerate(loader):\n",
    "            print(f\"  Batch {i}: tokens {batch['tokens'].shape}, labels {batch['labels'].shape}\")\n",
    "            batch_count += 1\n",
    "            if i >= 4:  # Only test first 5 batches\n",
    "                break\n",
    "        print(f\"  ✓ {loader_name} loader working ({batch_count} batches tested)\")\n",
    "    \n",
    "    print(\"✓ All data loaders test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b80524-e7c2-407a-b921-daea7f7cd310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PTMDataset with ./data/train.csv\n",
      "✓ ESM2 model loaded successfully\n",
      "✓ CSV loaded successfully\n",
      "48018\n",
      "Sample positions: [[36], None]\n",
      "Creating PTMDataset...\n",
      "✓ Dataset created successfully\n",
      "Dataset length: 48018\n",
      "Number of PTM types: 2\n",
      "\n",
      "Testing Dataset Items\n",
      "Testing first 5 dataset items...\n",
      "Item 0:\n",
      "  Sequence length: 79\n",
      "  Labels shape: torch.Size([79, 2])\n",
      "  Total PTMs: 1\n",
      "  PTM positions: ['PTM0: [36]', 'PTM1: []']\n",
      "\n",
      "Item 1:\n",
      "  Sequence length: 419\n",
      "  Labels shape: torch.Size([419, 2])\n",
      "  Total PTMs: 1\n",
      "  PTM positions: ['PTM0: []', 'PTM1: [115]']\n",
      "\n",
      "Item 2:\n",
      "  Sequence length: 80\n",
      "  Labels shape: torch.Size([80, 2])\n",
      "  Total PTMs: 1\n",
      "  PTM positions: ['PTM0: [38]', 'PTM1: []']\n",
      "\n",
      "Item 3:\n",
      "  Sequence length: 430\n",
      "  Labels shape: torch.Size([430, 2])\n",
      "  Total PTMs: 1\n",
      "  PTM positions: ['PTM0: []', 'PTM1: [116]']\n",
      "\n",
      "Item 4:\n",
      "  Sequence length: 418\n",
      "  Labels shape: torch.Size([418, 2])\n",
      "  Total PTMs: 1\n",
      "  PTM positions: ['PTM0: []', 'PTM1: [116]']\n",
      "\n",
      "Testing Collate Function\n",
      "Testing collate function with batch size 5...\n",
      "Input sequence lengths: [79, 419, 80, 430, 418]\n",
      "Collated batch contents:\n",
      "  Tokens shape: torch.Size([5, 432])\n",
      "  Labels shape: torch.Size([5, 432, 2])\n",
      "  Attention mask shape: torch.Size([5, 432])\n",
      "  Sequence lengths: [79, 419, 80, 430, 418]\n",
      "✓ Shapes are consistent\n",
      "Token analysis:\n",
      "  Padding token (1) count: 724\n",
      "  CLS token (0) count: 5\n",
      "  EOS token (2) count: 5\n",
      "  Attention mask sums (non-padding positions): [79.0, 419.0, 80.0, 430.0, 418.0]\n",
      "⚠️  Attention mask mismatch:\n",
      "    Expected: [81, 421, 82, 432, 420]\n",
      "    Actual: [79.0, 419.0, 80.0, 430.0, 418.0]\n",
      "\n",
      "Testing Data Loaders\n",
      "Loading ESM2 model...\n",
      "Loaded ESM2 model\n",
      "Creating data loaders...\n",
      "✓ Data loaders created successfully\n",
      "Testing train loader...\n",
      "  Batch 0: tokens torch.Size([5, 424]), labels torch.Size([5, 424, 2])\n",
      "  Batch 1: tokens torch.Size([5, 426]), labels torch.Size([5, 426, 2])\n",
      "  Batch 2: tokens torch.Size([5, 435]), labels torch.Size([5, 435, 2])\n",
      "  Batch 3: tokens torch.Size([5, 429]), labels torch.Size([5, 429, 2])\n",
      "  Batch 4: tokens torch.Size([5, 437]), labels torch.Size([5, 437, 2])\n",
      "  ✓ Train loader working (5 batches tested)\n",
      "Testing validation loader...\n",
      "  Batch 0: tokens torch.Size([5, 422]), labels torch.Size([5, 422, 2])\n",
      "  Batch 1: tokens torch.Size([5, 451]), labels torch.Size([5, 451, 2])\n",
      "  Batch 2: tokens torch.Size([5, 424]), labels torch.Size([5, 424, 2])\n",
      "  Batch 3: tokens torch.Size([5, 446]), labels torch.Size([5, 446, 2])\n",
      "  Batch 4: tokens torch.Size([5, 447]), labels torch.Size([5, 447, 2])\n",
      "  ✓ Validation loader working (5 batches tested)\n",
      "Testing test loader...\n",
      "  Batch 0: tokens torch.Size([5, 429]), labels torch.Size([5, 429, 2])\n",
      "  Batch 1: tokens torch.Size([5, 429]), labels torch.Size([5, 429, 2])\n",
      "  Batch 2: tokens torch.Size([5, 420]), labels torch.Size([5, 420, 2])\n",
      "  Batch 3: tokens torch.Size([5, 423]), labels torch.Size([5, 423, 2])\n",
      "  Batch 4: tokens torch.Size([5, 438]), labels torch.Size([5, 438, 2])\n",
      "  ✓ Test loader working (5 batches tested)\n",
      "✓ All data loaders test passed\n"
     ]
    }
   ],
   "source": [
    "dataset, alphabet, batch_converter = test_dataset_creation('./data/train.csv')\n",
    "test_dataset_items(dataset)\n",
    "test_collate_function(dataset, batch_converter)\n",
    "test_data_loaders(\"data/train.csv\", \"data/val.csv\", \"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e063ea00-a464-4eae-9a30-d425b03ba750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils.metrics import PTMMetrics, calculate_class_weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def test_ptm_metrics():\n",
    "    \"\"\"Test the PTMMetrics class with synthetic data\"\"\"\n",
    "    print(\"Testing PTMMetrics class...\")\n",
    "    \n",
    "    # Initialize metrics\n",
    "    num_ptm_types = 5\n",
    "    metrics = PTMMetrics(num_ptm_types)\n",
    "    \n",
    "    # Test 1: Perfect predictions\n",
    "    print(\"Test 1: Perfect predictions\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    # Create synthetic data\n",
    "    batch_size, seq_len = 5, 20\n",
    "    # In real ESM output, seq_len would include <cls> and <eos> tokens\n",
    "    # So actual sequence length would be seq_len + 2\n",
    "    total_len = seq_len + 2  # Adding <cls> at start and <eos> at end\n",
    "\n",
    "    labels = torch.randint(0, 2, (batch_size, total_len, num_ptm_types)).float()\n",
    "    predictions = labels.clone() # Make predictions match labels perfectly\n",
    "    \n",
    "    # Create mask that excludes <cls> (position 0) and <eos> (position seq_len+1)\n",
    "    mask = torch.ones(batch_size, total_len)\n",
    "    mask[:, 0] = 0  # Exclude <cls> token\n",
    "    mask[:, seq_len+1] = 0  # Exclude <eos> token\n",
    "\n",
    "    metrics.update(predictions, labels, mask)\n",
    "    results = metrics.compute(threshold=0.5)\n",
    "    \n",
    "    print(f\"Position accuracy: {results.get('position_accuracy', 0):.3f}\")\n",
    "    print(f\"Exact match accuracy: {results.get('exact_match_accuracy', 0):.3f}\")\n",
    "    print(f\"Overall F1: {results.get('overall_f1', 0):.3f}\")\n",
    "\n",
    "    # Test 2: Random predictions\n",
    "    print(\"Test 2: Random predictions\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    # Create more realistic data with imbalanced classes\n",
    "    # Include special tokens in the sequence length\n",
    "    total_len = seq_len + 2  # +2 for <cls> and <eos>\n",
    "    predictions = torch.sigmoid(torch.randn(batch_size, total_len, num_ptm_types))\n",
    "    labels = torch.zeros(batch_size, total_len, num_ptm_types)\n",
    "    \n",
    "    # Create mask excluding special tokens\n",
    "    mask = torch.ones(batch_size, total_len)\n",
    "    mask[:, 0] = 0  # <cls> token\n",
    "    mask[:, seq_len+1] = 0  # <eos> token\n",
    "\n",
    "    # Add some positive labels (simulate rare PTMs)\n",
    "    # Only add labels to valid amino acid positions (not special tokens)\n",
    "    for i in range(num_ptm_types):\n",
    "        num_positives = np.random.randint(1, 5)\n",
    "        # Only choose from valid positions (excluding positions 0 and seq_len+1)\n",
    "        valid_positions = []\n",
    "        for b in range(batch_size):\n",
    "            for s in range(1, seq_len+1):  # Skip position 0 (<cls>) and seq_len+1 (<eos>)\n",
    "                valid_positions.append((b, s))\n",
    "        \n",
    "        # Randomly select positions for positive labels\n",
    "        selected_positions = np.random.choice(len(valid_positions), \n",
    "                                            min(num_positives, len(valid_positions)), \n",
    "                                            replace=False)\n",
    "        \n",
    "        for pos_idx in selected_positions:\n",
    "            batch_idx, seq_idx = valid_positions[pos_idx]\n",
    "            labels[batch_idx, seq_idx, i] = 1\n",
    "\n",
    "    metrics.update(predictions, labels, mask)\n",
    "    results = metrics.compute(threshold=0.5)\n",
    "    \n",
    "    print(f\"Position accuracy: {results.get('position_accuracy', 0):.3f}\")\n",
    "    print(f\"Exact match accuracy: {results.get('exact_match_accuracy', 0):.3f}\")\n",
    "    print(f\"Overall F1: {results.get('overall_f1', 0):.3f}\")\n",
    "\n",
    "    # Print per-PTM metrics\n",
    "    print(\"Per-PTM metrics:\")\n",
    "    for i in range(num_ptm_types):\n",
    "        ptm_name = f\"PTM_{i}\"\n",
    "        if f'{ptm_name}_f1' in results:\n",
    "            print(f\"{ptm_name}: F1={results[f'{ptm_name}_f1']:.3f}, \"\n",
    "                  f\"Precision={results[f'{ptm_name}_precision']:.3f}, \"\n",
    "                  f\"Recall={results[f'{ptm_name}_recall']:.3f}\")\n",
    "\n",
    "    # Test 3: Testing with padding mask\n",
    "    print(\"Test 3: Testing with padding mask\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    # Create data with different sequence lengths (simulating padding)\n",
    "    batch_size, max_seq_len = 10, 30\n",
    "    # Total length includes <cls>, actual sequence, <eos>, and padding\n",
    "    total_max_len = max_seq_len + 2\n",
    "    predictions = torch.sigmoid(torch.randn(batch_size, total_max_len, num_ptm_types))\n",
    "    labels = torch.zeros(batch_size, total_max_len, num_ptm_types)\n",
    "    \n",
    "    # Create mask with different lengths\n",
    "    mask = torch.zeros(batch_size, total_max_len)\n",
    "    seq_lengths = [8,10,12,14,16,18,20,22,24,26]  # Different actual sequence lengths\n",
    "\n",
    "    for i, length in enumerate(seq_lengths):\n",
    "        # Set mask to 1 for valid amino acid positions only\n",
    "        # Position 0 is <cls>, positions 1 to length are amino acids, \n",
    "        # position length+1 is <eos>, rest is padding\n",
    "        mask[i, 1:length+1] = 1  # Only amino acid positions\n",
    "        \n",
    "        # Add some positive labels only in valid amino acid positions\n",
    "        for j in range(num_ptm_types):\n",
    "            if np.random.random() > 0.5:  # 50% chance of having this PTM\n",
    "                num_pos = np.random.randint(1, min(4, length))\n",
    "                # Choose positions between 1 and length (amino acid positions only)\n",
    "                positions = np.random.choice(range(1, length+1), num_pos, replace=False)\n",
    "                for pos in positions:\n",
    "                    labels[i, pos, j] = 1\n",
    "    \n",
    "    metrics.update(predictions, labels, mask)\n",
    "    results = metrics.compute(threshold=0.5)\n",
    "\n",
    "    print(f\"Position accuracy: {results.get('position_accuracy', 0):.3f}\")\n",
    "    print(f\"Overall F1: {results.get('overall_f1', 0):.3f}\")\n",
    "    \n",
    "    # Get PTM statistics\n",
    "    stats = metrics.get_per_ptm_stats()\n",
    "    print(\"PTM statistics:\")\n",
    "    for ptm_name, ptm_stats in stats.items():\n",
    "        print(f\"{ptm_name}: {ptm_stats['positive_samples']} positive, \"\n",
    "              f\"{ptm_stats['negative_samples']} negative \"\n",
    "              f\"(ratio: {ptm_stats['positive_ratio']:.3f})\")\n",
    "    print()\n",
    "\n",
    "def test_class_weights():\n",
    "    \"\"\"Test the calculate_class_weights function\"\"\"\n",
    "    print(\"Testing calculate_class_weights function...\")\n",
    "    \n",
    "    num_ptm_types = 4\n",
    "    positive_rates = [0.05, 0.20, 0.50, 0.7]  # 5%, 20%, 50% positive rates\n",
    "    \n",
    "    # Create fake data loader\n",
    "    data = []\n",
    "    for _ in range(5):  # 5 batches\n",
    "        batch_size = 7\n",
    "        seq_len = 20\n",
    "        total_len = seq_len + 2  # Add <cls> and <eos>\n",
    "        \n",
    "        labels = torch.zeros(batch_size, total_len, num_ptm_types)\n",
    "        mask = torch.zeros(batch_size, total_len)\n",
    "        mask[:, 1:seq_len+1] = 1  # Only amino acids are valid\n",
    "        \n",
    "        # Add positive labels based on rates\n",
    "        for ptm_idx, rate in enumerate(positive_rates):\n",
    "            for b in range(batch_size):\n",
    "                for pos in range(1, seq_len+1):\n",
    "                    if torch.rand(1).item() < rate:\n",
    "                        labels[b, pos, ptm_idx] = 1\n",
    "        \n",
    "        data.append({\n",
    "            'labels': labels,\n",
    "            'attention_mask': mask\n",
    "        })\n",
    "    \n",
    "    # Calculate weights\n",
    "    weights = calculate_class_weights(data, num_ptm_types, device='cpu')\n",
    "    \n",
    "    print(\"Class weights (negative, positive):\")\n",
    "    for i in range(num_ptm_types):\n",
    "        print(f\"PTM {i} (rate: {positive_rates[i]:.0%}): \"\n",
    "              f\"neg={weights[i, 0]:.3f}, pos={weights[i, 1]:.3f}\")\n",
    "    \n",
    "    print(\"Rarer PTMs should have higher positive weights:\")\n",
    "    print(f\"PTM 0 pos weight: {weights[0, 1]:.3f} (should be highest)\")\n",
    "    print(f\"PTM 1 pos weight: {weights[1, 1]:.3f} (should be middle)\")\n",
    "    print(f\"PTM 2 pos weight: {weights[2, 1]:.3f} (should be middle)\")\n",
    "    print(f\"PTM 3 pos weight: {weights[3, 1]:.3f} (should be lowest)\")\n",
    "    print()\n",
    "\n",
    "def test_edge_cases():\n",
    "    \"\"\"Test edge cases for the metrics\"\"\"\n",
    "    print(\"Testing edge cases...\")\n",
    "    \n",
    "    metrics = PTMMetrics(num_ptm_types=3)\n",
    "    \n",
    "    # Test 1: No positive samples for some PTMs\n",
    "    print(\"Test 1: No positive samples for PTM 1\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    predictions = torch.tensor([[[0.8, 0.2, 0.9], [0.1, 0.3, 0.7]]])\n",
    "    labels = torch.tensor([[[1, 0, 1], [0, 0, 1]]], dtype=torch.float)\n",
    "    mask = torch.ones(1, 2)\n",
    "    \n",
    "    metrics.update(predictions, labels, mask)\n",
    "    results = metrics.compute(threshold=0.5)\n",
    "    \n",
    "    # Should handle missing PTM gracefully\n",
    "    print(f\"Metrics computed successfully: {len(results)} metrics\")\n",
    "    print(f\"PTM_1 metrics present: {'PTM_1_f1' in results}\")\n",
    "    \n",
    "    # Test 2: All predictions are negative\n",
    "    print(\"Test 2: All predictions are negative\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    predictions = torch.zeros(2, 5, 3)  # All zeros\n",
    "    labels = torch.randint(0, 2, (2, 5, 3)).float()\n",
    "    mask = torch.ones(2, 5)\n",
    "    \n",
    "    metrics.update(predictions, labels, mask)\n",
    "    results = metrics.compute(threshold=0.5)\n",
    "    \n",
    "    print(f\"Overall recall (should be 0): {results.get('overall_recall', -1):.3f}\")\n",
    "    \n",
    "    # Test 3: Multiple batches\n",
    "    print(\"Test 3: Multiple batches accumulation\")\n",
    "    metrics.reset()\n",
    "    \n",
    "    for i in range(3):\n",
    "        predictions = torch.sigmoid(torch.randn(2, 10, 3))\n",
    "        labels = torch.randint(0, 2, (2, 10, 3)).float()\n",
    "        mask = torch.ones(2, 10)\n",
    "        metrics.update(predictions, labels, mask)\n",
    "    \n",
    "    results = metrics.compute()\n",
    "    stats = metrics.get_per_ptm_stats()\n",
    "    \n",
    "    total_samples = sum(stats[f'PTM_{i}']['positive_samples'] + \n",
    "                       stats[f'PTM_{i}']['negative_samples'] \n",
    "                       for i in range(3))\n",
    "    expected_samples = 3 * 2 * 10 * 3  # 3 batches * 2 batch_size * 10 seq_len * 3 PTMs\n",
    "    \n",
    "    print(f\"Total samples accumulated: {total_samples}\")\n",
    "    print(f\"Expected: {expected_samples}\")\n",
    "    print(f\"Correct accumulation: {total_samples == expected_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b37cc01-a22e-4135-9381-a773334a321c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PTMMetrics class...\n",
      "Test 1: Perfect predictions\n",
      "Position accuracy: 1.000\n",
      "Exact match accuracy: 1.000\n",
      "Overall F1: 1.000\n",
      "Test 2: Random predictions\n",
      "Position accuracy: 0.960\n",
      "Exact match accuracy: 0.060\n",
      "Overall F1: 0.046\n",
      "Per-PTM metrics:\n",
      "PTM_0: F1=0.041, Precision=0.021, Recall=0.500\n",
      "PTM_1: F1=0.077, Precision=0.040, Recall=1.000\n",
      "PTM_2: F1=0.035, Precision=0.018, Recall=1.000\n",
      "PTM_3: F1=0.035, Precision=0.019, Recall=0.333\n",
      "PTM_4: F1=0.042, Precision=0.021, Recall=1.000\n",
      "Test 3: Testing with padding mask\n",
      "Position accuracy: 0.947\n",
      "Overall F1: 0.095\n",
      "PTM statistics:\n",
      "PTM_0: 9 positive, 161 negative (ratio: 0.053)\n",
      "PTM_1: 9 positive, 161 negative (ratio: 0.053)\n",
      "PTM_2: 18 positive, 152 negative (ratio: 0.106)\n",
      "PTM_3: 6 positive, 164 negative (ratio: 0.035)\n",
      "PTM_4: 8 positive, 162 negative (ratio: 0.047)\n",
      "\n",
      "Testing calculate_class_weights function...\n",
      "Class weights (negative, positive):\n",
      "PTM 0 (rate: 5%): neg=0.039, pos=0.961\n",
      "PTM 1 (rate: 20%): neg=0.187, pos=0.813\n",
      "PTM 2 (rate: 50%): neg=0.476, pos=0.524\n",
      "PTM 3 (rate: 70%): neg=0.701, pos=0.299\n",
      "Rarer PTMs should have higher positive weights:\n",
      "PTM 0 pos weight: 0.961 (should be highest)\n",
      "PTM 1 pos weight: 0.813 (should be middle)\n",
      "PTM 2 pos weight: 0.524 (should be middle)\n",
      "PTM 3 pos weight: 0.299 (should be lowest)\n",
      "\n",
      "Testing edge cases...\n",
      "Test 1: No positive samples for PTM 1\n",
      "Metrics computed successfully: 12 metrics\n",
      "PTM_1 metrics present: False\n",
      "Test 2: All predictions are negative\n",
      "Overall recall (should be 0): 0.000\n",
      "Test 3: Multiple batches accumulation\n",
      "Total samples accumulated: 180\n",
      "Expected: 180\n",
      "Correct accumulation: True\n"
     ]
    }
   ],
   "source": [
    "test_ptm_metrics()\n",
    "test_class_weights()\n",
    "test_edge_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbc017-92b8-48dc-afd9-ca4a627f0340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
